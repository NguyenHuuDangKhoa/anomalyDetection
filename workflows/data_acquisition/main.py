"""
The get_data function should load the raw data in any format from any place and return it
"""
from argparse import ArgumentParser, Namespace
from pathlib import Path
from typing import Dict
from dotenv import load_dotenv
import structlog
import os

from project_core.data.acquisition import acquisition
from project_core.utils import load_yaml_config

logger = structlog.getLogger(__name__)


def parse_arguments() -> Namespace:
    """
    This function parses the argurments for the command-line used in Makefile for automation.
    :return: a Namespace that defines all required argurments in the command-line in Makefile
    """
    parser = ArgumentParser(prog=f'{__name__} of data acquisition')
    parser.add_argument('--config_file_name', required=True, type=str, help='Name of the data acquisition config file')
    # We want to use a list of str as input for the data parameter so nargs='*' is used for multiple inputs
    parser.add_argument('--data', required=True, nargs='*', type=str, help='List of data to be downloaded')
    parser.add_argument('--action', required=True,
                        choices=['download_raw_csv', 'download_blob_name', 'download_blob'], type=str,
                        help='Action for data instance to perform')
    return parser.parse_args()


def get_attribute(config_yaml: Dict, data: str) -> Dict:
    """
    This function reads the YAML and .env files to get all the secret environment variables.
    :param config_yaml: a dictionary generated by reading a config YAML file
    :param data: name of a data need to be downloaded
    :return: a dictionary with data name as keys and secret information as values
    """
    class_attributes_dict = config_yaml['data_acquisition_settings'][data]
    for key in class_attributes_dict.keys():
        class_attributes_dict[key] = os.getenv(config_yaml['data_acquisition_settings'][data][key])
    return class_attributes_dict


def create_data_instance(config_yaml: Dict, data: str) -> acquisition.BlobData:
    """
    This function creates data instances that are responsible for downloading, converting, and saving data.
    :param config_yaml: a dictionary generated by reading a config YAML file
    :param data: name of a data need to be downloaded
    :return: a data instance of the BlobData class
    """
    class_attribute_dict = get_attribute(config_yaml=config_yaml, data=data)
    data_instance = acquisition.BlobData(
        connect_str=os.getenv(config_yaml['data_acquisition_settings']['general_settings']['connect_str']),
        container_name=os.getenv(config_yaml['data_acquisition_settings']['general_settings']['container_name']),
        uri_type=class_attribute_dict['uri_type'],
        datastore_uri=class_attribute_dict['datastore_uri'],
        blob_name=class_attribute_dict['blob_name']
    )
    return data_instance


def main() -> None:
    """
    Main function that runs the data acquisition process.
    """
    logger.info('Acquiring data...')
    logger.info('Parsing arguments input from the command-line...')
    arguments = parse_arguments()
    config_path = Path(os.path.join(Path(__file__).parent, arguments.config_file_name))
    logger.info('Loading the configuration for data processing...')
    config = load_yaml_config(config_path=config_path)
    logger.info('Loading all the environment variables...')
    load_dotenv()
    if arguments.action == 'download_blob':
        for data in arguments.data:
            logger.info(f'Processing {data}:')
            _data_instance = create_data_instance(config_yaml=config, data=data)
            _data_instance._download_from_blob_storage(
                file_name=f'{data.split("__")[0]}_download.{data.split("__")[1]}')
            logger.info('******************')
        logger.info('Data Acquisition Finished')
    elif arguments.action == 'download_blob_name':
        logger.info('Downloading a list of all blob names on Azure Blob Storage')
        # Any data instance can get the container client
        _data_instance = create_data_instance(config_yaml=config, data=arguments.data[0])
        _data_instance._BlobData__get_blob_names(file_name='blob_names.txt')
        logger.info('******************')
        logger.info('Finished downloading blob names')
    elif arguments.action == 'download_raw_csv':
        # change to argurments.data[:2] if you only want to download the first 2 files
        for data in arguments.data:
            logger.info(f'Processing raw {data}:')
            _data_instance = create_data_instance(config_yaml=config, data=data)
            _data_instance._convert_pandas_dataframe_to_feather(
                file_name=f'{data.split("__")[0]}.{data.split("__")[1]}')
            logger.info('******************')
        logger.info('Raw Data Acquisition Finished')


if __name__ == '__main__':
    main()
